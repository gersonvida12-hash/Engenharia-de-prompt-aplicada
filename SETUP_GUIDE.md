# Guia de Instala√ß√£o - Interface LLaMA Desktop para Windows 11 Pro

Este guia o ajudar√° a instalar e configurar a Interface LLaMA Desktop em seu sistema Windows 11 Pro.

## üéØ Instala√ß√£o R√°pida (Usu√°rio Final)

### 1. Pr√©-requisitos Essenciais

#### Ollama (Obrigat√≥rio)
1. **Baixe o Ollama para Windows:**
   - Acesse: https://ollama.ai/download/windows
   - Execute o instalador `ollama-windows-amd64.exe`
   - Siga as instru√ß√µes de instala√ß√£o

2. **Configure o Ollama:**
   ```cmd
   # Abra o Command Prompt ou PowerShell como Administrador
   ollama serve
   ```
   > ‚ö†Ô∏è **Importante**: Mantenha esta janela aberta enquanto usar a aplica√ß√£o!

3. **Instale um modelo LLaMA:**
   ```cmd
   # Escolha UM dos modelos abaixo (recomenda√ß√£o: llama3 para melhor desempenho)
   ollama pull llama3       # Mais recente e eficiente (~4.7GB)
   ollama pull llama2       # Mais est√°vel (~3.8GB)
   ollama pull mistral      # Mais r√°pido (~4.1GB)
   ```

### 2. Instala√ß√£o da Aplica√ß√£o

#### Op√ß√£o A: Execut√°vel Pronto (Recomendado)
1. Baixe `Interface-LLaMA-Desktop-Setup.exe` da se√ß√£o Releases
2. Execute como administrador
3. Siga o assistente de instala√ß√£o
4. Encontre o √≠cone no Desktop ou Menu Iniciar

#### Op√ß√£o B: Build Manual
1. **Instale Node.js:**
   - Baixe: https://nodejs.org/ (vers√£o LTS)
   - Execute o instalador

2. **Baixe o c√≥digo:**
   ```cmd
   git clone https://github.com/gersonvida12-hash/Engenharia-de-prompt-aplicada.git
   cd Engenharia-de-prompt-aplicada
   ```

3. **Instale e construa:**
   ```cmd
   npm install
   npm run dist:win
   ```

4. **Execute:**
   - Encontre o `.exe` na pasta `release/`

## üöÄ Primeiro Uso

### 1. Inicie o Sistema
```cmd
# Terminal 1: Inicie o Ollama
ollama serve

# Aguarde a mensagem: "Ollama is running on http://localhost:11434"
```

### 2. Execute a Aplica√ß√£o
- Clique duplo no √≠cone "Interface LLaMA Desktop"
- Ou execute o `.exe` da pasta de instala√ß√£o

### 3. Verifique a Conex√£o
- Status deve mostrar: ‚úÖ "Conectado ao LLaMA"
- Se n√£o conectar, clique em "Testar Conex√£o"

### 4. Teste B√°sico
1. Selecione um modelo no dropdown
2. Digite: "Ol√°! Como voc√™ funciona?"
3. Clique "Enviar"
4. Aguarde a resposta

## üìä Monitoramento do Sistema

### Verificar se Ollama est√° Rodando:
```cmd
# Abra Command Prompt e digite:
curl http://localhost:11434/api/tags
# Ou no navegador: http://localhost:11434/api/tags
```

### Verificar Modelos Instalados:
```cmd
ollama list
```

### Verificar Uso de Recursos:
- **Task Manager** ‚Üí Aba "Performance"
- Ollama usa significativa CPU/RAM durante processamento

## üîß Configura√ß√µes Avan√ßadas

### Configurar Ollama para Iniciar Automaticamente:

1. **Windows Services:**
   ```cmd
   # Execute como Administrador
   sc create OllamaService binPath="C:\Users\%USERNAME%\AppData\Local\Programs\Ollama\ollama.exe serve" start=auto
   sc start OllamaService
   ```

2. **Task Scheduler:**
   - Abra "Task Scheduler"
   - Criar Tarefa B√°sica
   - Trigger: "When computer starts"
   - Action: `ollama.exe serve`

### Configurar Modelos Customizados:

1. **Criar Modelfile:**
   ```dockerfile
   # Arquivo: Modelfile
   FROM llama3
   SYSTEM "Voc√™ √© um assistente especializado em [sua √°rea]"
   ```

2. **Criar modelo customizado:**
   ```cmd
   ollama create meu-modelo -f Modelfile
   ```

### Configurar GPU (NVIDIA):
```cmd
# Verificar se GPU est√° dispon√≠vel
nvidia-smi

# Ollama detectar√° automaticamente GPU compat√≠vel
# Verifique logs durante inicializa√ß√£o
```

## üõ† Solu√ß√£o de Problemas Detalhada

### Problema: "N√£o foi poss√≠vel conectar ao LLaMA local"

**Solu√ß√µes:**
1. **Verificar Ollama:**
   ```cmd
   # Verificar se est√° rodando
   tasklist | findstr ollama
   
   # Se n√£o estiver, iniciar
   ollama serve
   ```

2. **Verificar Firewall:**
   - Windows Defender Firewall
   - Adicionar exce√ß√£o para porta 11434
   - Adicionar exce√ß√£o para ollama.exe

3. **Verificar Antiv√≠rus:**
   - Adicionar ollama.exe √† lista de exce√ß√µes
   - Adicionar pasta de instala√ß√£o √†s exce√ß√µes

### Problema: "Nenhum modelo dispon√≠vel"

**Solu√ß√µes:**
1. **Instalar modelos:**
   ```cmd
   ollama pull llama3
   ollama list  # Verificar instala√ß√£o
   ```

2. **Verificar espa√ßo em disco:**
   - Modelos ocupam 3-8GB cada
   - Verificar espa√ßo livre suficiente

### Problema: Performance lenta

**Solu√ß√µes:**
1. **Verificar recursos:**
   - RAM: M√≠nimo 8GB, recomendado 16GB+
   - CPU: Usar modelos menores se necess√°rio

2. **Otimizar modelo:**
   ```cmd
   # Use modelos menores
   ollama pull tinyllama    # Modelo pequeno (~637MB)
   ```

3. **Configurar prioridade:**
   - Task Manager ‚Üí Ollama process ‚Üí Set Priority ‚Üí High

### Problema: Execut√°vel n√£o inicia

**Solu√ß√µes:**
1. **Verificar depend√™ncias:**
   - Visual C++ Redistributables instalados
   - Windows 11 atualizado

2. **Executar como administrador:**
   - Clique direito ‚Üí "Run as administrator"

3. **Verificar logs:**
   - Localiza√ß√£o: `%APPDATA%/interface-llama-desktop/logs/`

## üìã Checklist de Instala√ß√£o Completa

- [ ] Windows 11 Pro instalado e atualizado
- [ ] Ollama baixado e instalado
- [ ] Pelo menos um modelo LLaMA baixado
- [ ] Ollama service rodando (`ollama serve`)
- [ ] Interface LLaMA Desktop instalada
- [ ] Teste de conex√£o bem-sucedido
- [ ] Teste de chat b√°sico funcionando
- [ ] Teste de upload de arquivo funcionando

## üÜò Suporte Adicional

### Logs e Diagn√≥sticos:
```cmd
# Verificar logs do Ollama
ollama logs

# Verificar status detalhado
ollama ps

# Informa√ß√µes do sistema
systeminfo | findstr /B /C:"OS Name" /C:"Total Physical Memory"
```

### Contatos de Suporte:
- **GitHub Issues**: https://github.com/gersonvida12-hash/Engenharia-de-prompt-aplicada/issues
- **Documenta√ß√£o Ollama**: https://ollama.ai/docs
- **Comunidade**: Discord/Forums espec√≠ficos

### Backup e Restaura√ß√£o:
```cmd
# Backup de modelos (opcional)
xcopy "%USERPROFILE%\.ollama" "C:\Backup\ollama" /E /I

# Restaurar modelos
xcopy "C:\Backup\ollama" "%USERPROFILE%\.ollama" /E /I
```

---

## üéâ Conclus√£o

Ap√≥s seguir este guia, voc√™ ter√°:
- ‚úÖ Sistema LLaMA local funcionando
- ‚úÖ Interface desktop moderna e intuitiva  
- ‚úÖ Capacidade de processamento multimodal
- ‚úÖ Configura√ß√£o otimizada para Windows 11 Pro

**Pr√≥ximos Passos:**
1. Experimente diferentes modelos
2. Teste uploads de diferentes tipos de arquivo
3. Explore configura√ß√µes avan√ßadas conforme necessidade

Aproveite sua nova interface LLaMA Desktop! üöÄ